version: "3.8"

x-clickhouse-defaults: &clickhouse-defaults
  restart: on-failure
  image: clickhouse/clickhouse-server:24.1.2-alpine
  tty: true
  depends_on:
    - zookeeper-1
  logging:
    options:
      max-size: 50m
      max-file: "3"
  healthcheck:
    test:
      [
        "CMD",
        "wget",
        "--spider",
        "-q",
        "localhost:8123/ping"
      ]
    interval: 30s
    timeout: 5s
    retries: 3
  ulimits:
    nproc: 65535
    nofile:
      soft: 262144
      hard: 262144

x-db-depend: &db-depend
  depends_on:
    clickhouse:
      condition: service_healthy
    otel-collector-migrator:
      condition: service_completed_successfully

services:
  zookeeper-1:
    image: bitnami/zookeeper:3.7.1
    container_name: signoz-zookeeper-1
    hostname: zookeeper-1
    user: root
    ports:
      - "2181:2181"
      - "2888:2888"
      - "3888:3888"
    volumes:
      - ./signoz/data/zookeeper-1:/bitnami/zookeeper
    environment:
      - ZOO_SERVER_ID=1
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_AUTOPURGE_INTERVAL=1
    networks:
      gymz-net:
        aliases:
          - zookeeper-1

  clickhouse:
    <<: *clickhouse-defaults
    container_name: signoz-clickhouse
    hostname: clickhouse
    ports:
      - "9000:9000"
      - "8123:8123"
      - "9181:9181"
    volumes:
      - ./signoz/clickhouse-config.xml:/etc/clickhouse-server/config.xml
      - ./signoz/clickhouse-users.xml:/etc/clickhouse-server/users.xml
      - ./signoz/custom-function.xml:/etc/clickhouse-server/custom-function.xml
      - ./signoz/clickhouse-cluster.xml:/etc/clickhouse-server/config.d/cluster.xml
      - ./signoz/data/clickhouse/:/var/lib/clickhouse/
      - ./signoz/user_scripts:/var/lib/clickhouse/user_scripts/
    networks:
      gymz-net:
        aliases:
          - clickhouse

  alertmanager:
    image: signoz/alertmanager:${ALERTMANAGER_TAG:-0.23.5}
    container_name: signoz-alertmanager
    volumes:
      - ./signoz/data/alertmanager:/data
    depends_on:
      query-service:
        condition: service_healthy
    restart: on-failure
    networks:
      gymz-net:
        aliases:
          - alertmanager
    command:
      - --queryService.url=http://query-service:8085
      - --storage.path=/data

  query-service:
    image: signoz/query-service:${DOCKER_TAG:-0.39.0}
    container_name: signoz-query-service
    command:
      [
        "-config=/root/config/prometheus.yml",
      ]
    volumes:
      - ./signoz/prometheus.yml:/root/config/prometheus.yml
      - ./signoz/dashboards:/root/config/dashboards
      - ./signoz/data/signoz/:/var/lib/signoz/
    environment:
      - ClickHouseUrl=tcp://clickhouse:9000
      - ALERTMANAGER_API_PREFIX=http://alertmanager:9093/api/
      - SIGNOZ_LOCAL_DB_PATH=/var/lib/signoz/signoz.db
      - DASHBOARDS_PATH=/root/config/dashboards
      - STORAGE=clickhouse
      - GODEBUG=netdns=go
      - TELEMETRY_ENABLED=true
      - DEPLOYMENT_TYPE=docker-standalone-amd
    restart: on-failure
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--spider",
          "-q",
          "localhost:8080/api/v1/health"
        ]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      gymz-net:
        aliases:
          - query-service
    <<: *db-depend

  frontend:
    image: signoz/frontend:${DOCKER_TAG:-0.39.0}
    container_name: signoz-frontend
    restart: on-failure
    depends_on:
      - alertmanager
      - query-service
    ports:
      - "3301:3301"
    volumes:
      - ./signoz/nginx-config.conf:/etc/nginx/conf.d/default.conf
    networks:
      gymz-net:
        aliases:
          - frontend

  otel-collector-migrator:
    image: signoz/signoz-schema-migrator:${OTELCOL_TAG:-0.88.12}
    container_name: otel-migrator
    command:
      - "--dsn=tcp://clickhouse:9000"
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      gymz-net:
        aliases:
          - otel-collector-migrator

  otel-collector:
    image: signoz/signoz-otel-collector:${OTELCOL_TAG:-0.88.12}
    container_name: signoz-otel-collector
    command:
      [
        "--config=/etc/otel-collector-config.yaml",
        "--manager-config=/etc/manager-config.yaml",
        "--copy-path=/var/tmp/collector-config.yaml",
        "--feature-gates=-pkg.translator.prometheus.NormalizeName"
      ]
    user: root # required for reading docker container logs
    volumes:
      - ./signoz/otel-collector-config.yaml:/etc/otel-collector-config.yaml
      - ./signoz/otel-collector-opamp-config.yaml:/etc/manager-config.yaml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name=signoz-host,os.type=linux
      - DOCKER_MULTI_NODE_CLUSTER=false
      - LOW_CARDINAL_EXCEPTION_GROUPING=false
    ports:
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
    restart: on-failure
    depends_on:
      clickhouse:
        condition: service_healthy
      otel-collector-migrator:
        condition: service_completed_successfully
      query-service:
        condition: service_healthy
    networks:
      gymz-net:
        aliases:
          - otel-collector

  logspout:
    image: "gliderlabs/logspout:v3.2.14"
    container_name: signoz-logspout
    volumes:
      - /etc/hostname:/etc/host_hostname:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: syslog+tcp://otel-collector:2255
    depends_on:
      - otel-collector
    restart: on-failure
    networks:
      gymz-net:
        aliases:
          - logspout

  zitadel:
    restart: 'always'
    networks:
      gymz-net:
        aliases:
          - zitadel
    image: 'ghcr.io/zitadel/zitadel:latest'
    command: 'start-from-init --masterkey "MasterkeyNeedsToHave32Characters" --tlsMode disabled'
    environment:
      - 'ZITADEL_DATABASE_POSTGRES_HOST=zitadel-db'
      - 'ZITADEL_DATABASE_POSTGRES_PORT=5432'
      - 'ZITADEL_DATABASE_POSTGRES_DATABASE=zitadel'
      - 'ZITADEL_DATABASE_POSTGRES_USER_USERNAME=zitadel'
      - 'ZITADEL_DATABASE_POSTGRES_USER_PASSWORD=zitadel'
      - 'ZITADEL_DATABASE_POSTGRES_USER_SSL_MODE=disable'
      - 'ZITADEL_DATABASE_POSTGRES_ADMIN_USERNAME=postgres'
      - 'ZITADEL_DATABASE_POSTGRES_ADMIN_PASSWORD=postgres'
      - 'ZITADEL_DATABASE_POSTGRES_ADMIN_SSL_MODE=disable'
      - 'ZITADEL_EXTERNALSECURE=false'
    depends_on:
      zitadel-db:
        condition: 'service_healthy'
    ports:
      - '8080:8080'

  zitadel-db:
    restart: 'always'
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    networks:
      gymz-net:
        aliases:
          - zitadel-db
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      interval: '10s'
      timeout: '30s'
      retries: 5
      start_period: '20s'
    ports:
      - '5432:5432'

  gymz-app:
     image: gymz-app:local
     ports:
       - "8081:8081"
     environment:
       - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
       - OTEL_LOGS_EXPORTER=otlp
       - OTEL_METRICS_EXPORTER=otlp
       - OTEL_RESOURCE_ATTRIBUTES=service.name=gymz-app,service.version=local
       - OTEL_METRICS_URL=http://otel-collector:4318/v1/metrics
       - MONITORING_ENABLED=true
       - ZITADEL_BASE_URL=http://zitadel:8080
       - ZITADEL_CLIENT_ID=257998435137945605@gymz
       - ZITADEL_CLIENT_SECRET=aaJ0vrYYmoqtf2jWrq7BGlxu48t11k67kacwHiANsKMzMS3XlQV42QHqSBSXy0kw
     depends_on:
       otel-collector:
         condition: service_started
     networks:
       gymz-net:
         aliases:
           - gymz-app

networks:
  gymz-net:
    driver: bridge
    ipam:
      config:
        - subnet: 10.7.0.0/16
